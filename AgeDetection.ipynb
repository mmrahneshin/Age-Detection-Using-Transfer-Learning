{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we tend to predict the age of individuals with respect to the image of their face by transfer learnign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B5xzh0ICIwSS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn \n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Transform on data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomVerticalFlip()\n",
    "           ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# getting data\n",
    "data_dir = '/home/sepehr/neuralNetworks/Dataset/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_dataloader = dataloaders['train']\n",
    "images, labels = next(iter(train_dataloader))\n",
    "print(images.shape)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i put relu and dropout layer in my model for using structure as same as VGG classifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module) :\n",
    "  def __init__(self, input_size, num_classes=5):\n",
    "    super(NeuralNetwork, self).__init__()\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.dropout = nn.Dropout(p=0.5,inplace=False)\n",
    "    self.fc = nn.Linear(in_features=input_size,out_features=5)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x = self.relu(x)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i set true req_grad of two conv layer for learning some feature.\n",
    "i reach to this model of vgg with several test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVggWithNeuralNetwork(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=5):\n",
    "        super(CustomVggWithNeuralNetwork, self).__init__()\n",
    "\n",
    "        self.vgg = models.vgg16(pretrained=pretrained)\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.vgg.features[0:2].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.vgg.features[5:7].parameters():\n",
    "            param.requires_grad = True\n",
    "        self.base_network = NeuralNetwork(1000, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg(x)\n",
    "        x = self.base_network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.eval of CustomVggWithNeuralNetwork(\n",
      "  (vgg): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (base_network): NeuralNetwork(\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (fc): Linear(in_features=1000, out_features=5, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "combined_model = CustomVggWithNeuralNetwork(pretrained=True)\n",
    "print(combined_model.eval)\n",
    "# print(combined_model)\n",
    "combined_model = combined_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4_WqCcUYal1t"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'test']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'test' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best test Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 2.1940 Acc: 0.1855\n",
      "test Loss: 1.9343 Acc: 0.2400\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 2.3276 Acc: 0.1613\n",
      "test Loss: 1.9702 Acc: 0.1600\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 2.0066 Acc: 0.2500\n",
      "test Loss: 1.6199 Acc: 0.2400\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.8549 Acc: 0.2500\n",
      "test Loss: 1.6759 Acc: 0.2800\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.6896 Acc: 0.2984\n",
      "test Loss: 1.7129 Acc: 0.2400\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.6446 Acc: 0.3629\n",
      "test Loss: 1.6190 Acc: 0.2400\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.7788 Acc: 0.2984\n",
      "test Loss: 1.6374 Acc: 0.2000\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.8603 Acc: 0.2742\n",
      "test Loss: 1.5866 Acc: 0.2400\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.6240 Acc: 0.3710\n",
      "test Loss: 1.5769 Acc: 0.2800\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.5454 Acc: 0.3710\n",
      "test Loss: 1.5642 Acc: 0.2400\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.4676 Acc: 0.3710\n",
      "test Loss: 1.5747 Acc: 0.2800\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.6002 Acc: 0.3226\n",
      "test Loss: 1.5682 Acc: 0.2400\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.5995 Acc: 0.3468\n",
      "test Loss: 1.5736 Acc: 0.3200\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.5753 Acc: 0.3710\n",
      "test Loss: 1.5627 Acc: 0.3200\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.6013 Acc: 0.3629\n",
      "test Loss: 1.5632 Acc: 0.3200\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.5278 Acc: 0.3871\n",
      "test Loss: 1.5646 Acc: 0.3200\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.4867 Acc: 0.3629\n",
      "test Loss: 1.5644 Acc: 0.3200\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.5043 Acc: 0.3790\n",
      "test Loss: 1.5642 Acc: 0.3200\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.4660 Acc: 0.3790\n",
      "test Loss: 1.5649 Acc: 0.3200\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.4981 Acc: 0.3306\n",
      "test Loss: 1.5655 Acc: 0.3200\n",
      "\n",
      "Training complete in 3m 34s\n",
      "Best test Acc: 0.320000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomVggWithNeuralNetwork(\n",
       "  (vgg): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (base_network): NeuralNetwork(\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Linear(in_features=1000, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss function\n",
    "loss = nn.CrossEntropyLoss()\n",
    "combined_model.zero_grad()\n",
    "# optimizer\n",
    "optimizer = optim.SGD(params=combined_model.parameters() , lr= 0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# training \n",
    "train_model(combined_model , loss , optimizer ,exp_lr_scheduler, num_epochs= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i reach very low acc beacause we have very very little data but my model show learn something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 32.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "combined_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dataloaders['test']:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = combined_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset_crop\n",
    "\n",
    "in this section i crop face to decrease noise and reach higher acc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def crop_faces_folder(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load the pre-trained face detector from OpenCV\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Iterate over all image files in the input folder\n",
    "    for foldername in os.listdir(input_folder):\n",
    "        for filename in os.listdir(os.path.join(input_folder, foldername)):\n",
    "\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Add more extensions if needed\n",
    "                # Load the image\n",
    "                # print(foldername)\n",
    "                image_path = os.path.join(input_folder,foldername, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detect faces in the image\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "                # Crop and save each face\n",
    "                for i, (x, y, w, h) in enumerate(faces):\n",
    "                    face_roi = image[y:y + h, x:x + w]\n",
    "                    output_path = os.path.join(output_folder,foldername, f\"{filename}\")\n",
    "                    cv2.imwrite(output_path, face_roi)\n",
    "\n",
    "# Example usage\n",
    "input_folder_train = '/home/sepehr/neuralNetworks/Dataset/train'\n",
    "output_folder_train = '/home/sepehr/neuralNetworks/Dataset_crop/train'\n",
    "input_folder_test = '/home/sepehr/neuralNetworks/Dataset/test'\n",
    "output_folder_test = '/home/sepehr/neuralNetworks/Dataset_crop/test'\n",
    "crop_faces_folder(input_folder_train, output_folder_train)\n",
    "crop_faces_folder(input_folder_test, output_folder_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Transform on data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomVerticalFlip()\n",
    "           ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# getting data\n",
    "data_dir = '/home/sepehr/neuralNetworks/Dataset_crop/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_dataloader = dataloaders['train']\n",
    "images, labels = next(iter(train_dataloader))\n",
    "print(images.shape)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.5922 Acc: 0.3429\n",
      "test Loss: 1.8375 Acc: 0.1905\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.4481 Acc: 0.3714\n",
      "test Loss: 1.7594 Acc: 0.2381\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.6336 Acc: 0.3714\n",
      "test Loss: 1.8387 Acc: 0.1905\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.6222 Acc: 0.3429\n",
      "test Loss: 1.9152 Acc: 0.1429\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.5564 Acc: 0.3619\n",
      "test Loss: 1.7889 Acc: 0.1429\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.5052 Acc: 0.3524\n",
      "test Loss: 1.7489 Acc: 0.3333\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.5061 Acc: 0.2667\n",
      "test Loss: 1.8743 Acc: 0.2857\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.3311 Acc: 0.4476\n",
      "test Loss: 1.7445 Acc: 0.3333\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.4718 Acc: 0.3714\n",
      "test Loss: 1.6985 Acc: 0.3810\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.3884 Acc: 0.4000\n",
      "test Loss: 1.6998 Acc: 0.3810\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.4192 Acc: 0.3810\n",
      "test Loss: 1.6829 Acc: 0.3810\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.4264 Acc: 0.4762\n",
      "test Loss: 1.6865 Acc: 0.3810\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.5552 Acc: 0.3429\n",
      "test Loss: 1.6668 Acc: 0.4286\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.4981 Acc: 0.3714\n",
      "test Loss: 1.6772 Acc: 0.3810\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.5283 Acc: 0.3714\n",
      "test Loss: 1.6754 Acc: 0.3810\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.3115 Acc: 0.4381\n",
      "test Loss: 1.6770 Acc: 0.3810\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.3381 Acc: 0.4381\n",
      "test Loss: 1.6759 Acc: 0.3810\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.4094 Acc: 0.3810\n",
      "test Loss: 1.6751 Acc: 0.3810\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.4734 Acc: 0.3429\n",
      "test Loss: 1.6735 Acc: 0.3810\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.5012 Acc: 0.3238\n",
      "test Loss: 1.6728 Acc: 0.3810\n",
      "\n",
      "Training complete in 2m 49s\n",
      "Best test Acc: 0.428571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomVggWithNeuralNetwork(\n",
       "  (vgg): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (base_network): NeuralNetwork(\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Linear(in_features=1000, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss function\n",
    "loss = nn.CrossEntropyLoss()\n",
    "combined_model.zero_grad()\n",
    "# optimizer\n",
    "optimizer = optim.SGD(params=combined_model.parameters() , lr= 0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# training \n",
    "train_model(combined_model , loss , optimizer ,exp_lr_scheduler, num_epochs= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with cropped image the acc increase 10% and this result show again my model learn something of this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 42.86%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "combined_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in dataloaders['test']:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = combined_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
